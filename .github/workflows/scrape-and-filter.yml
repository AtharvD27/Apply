name: Scrape & Filter Dice Jobs

on:
  schedule:
    - cron: '0 11 * * *'  # 7 AM EST
    - cron: '0 16 * * *'  # 12 PM EST
    - cron: '0 21 * * *'  # 5 PM EST
  workflow_dispatch:

jobs:
  scrape_and_filter:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3
      with:
        persist-credentials: false
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Chrome v135 and matching Chromedriver
      run: |
        set -e
        sudo apt-get update
    
        # Install Chrome 135 manually
        wget https://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_135.0.7049.114-1_amd64.deb
        sudo dpkg -i google-chrome-stable_135.0.7049.114-1_amd64.deb || sudo apt-get -f install -y
    
        # Install Chromedriver 135
        wget https://chromedriver.storage.googleapis.com/135.0.7049.114/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver
    
        # Verify versions
        google-chrome --version
        chromedriver --version


    - name: Run main.py to scrape and filter
      env:
        SCRAPER_EMAIL: ${{ secrets.SCRAPER_EMAIL }}
        SCRAPER_PASSWORD: ${{ secrets.SCRAPER_PASSWORD }}
        BASE_URL: ${{ secrets.BASE_URL }}
      run: python main.py

    - name: Commit and push updated job files
      run: |
        git config --global user.name "github-actions"
        git config --global user.email "github-actions@github.com"
        git add output/jobs.csv output/final_ml_jobs.csv

        if git diff --cached --quiet; then
          echo "No changes to commit."
        else
          git commit -m "ðŸ”„ Auto-update jobs.csv and final_ml_jobs.csv"
          git push https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:${{ github.ref }}
